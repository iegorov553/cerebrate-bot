#!/usr/bin/env python3
"""
–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º —Å Markdown –≤ –ø–µ—Ä–µ–≤–æ–¥–∞—Ö.
–≠–∫—Ä–∞–Ω–∏—Ä—É–µ—Ç —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è.
"""

import json
import re
from pathlib import Path
from typing import Dict, Any

class MarkdownFixer:
    def __init__(self):
        # –°–∏–º–≤–æ–ª—ã, –∫–æ—Ç–æ—Ä—ã–µ –Ω—É–∂–Ω–æ —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞—Ç—å –¥–ª—è MarkdownV2
        self.escape_chars = {
            '_': '\\_',
            '*': '\\*',
            '[': '\\[',
            ']': '\\]',
            '(': '\\(',
            ')': '\\)',
            '~': '\\~',
            '`': '\\`',
            '>': '\\>',
            '#': '\\#',
            '+': '\\+',
            '-': '\\-',
            '=': '\\=',
            '|': '\\|',
            '{': '\\{',
            '}': '\\}',
            '.': '\\.',
            '!': '\\!'
        }
    
    def escape_markdown(self, text: str) -> str:
        """–≠–∫—Ä–∞–Ω–∏—Ä—É–µ—Ç —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã Markdown."""
        if not text:
            return text
        
        # –ù–µ —ç–∫—Ä–∞–Ω–∏—Ä—É–µ–º, –µ—Å–ª–∏ —ç—Ç–æ —É–∂–µ —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
        if '\\' in text:
            return text
        
        # –ù–µ —ç–∫—Ä–∞–Ω–∏—Ä—É–µ–º –∫–æ–¥ –≤ –æ–±—Ä–∞—Ç–Ω—ã—Ö –∫–∞–≤—ã—á–∫–∞—Ö
        if '`' in text and text.count('`') >= 2:
            return text
        
        # –ù–µ —ç–∫—Ä–∞–Ω–∏—Ä—É–µ–º –∂–∏—Ä–Ω—ã–π —Ç–µ–∫—Å—Ç –≤ **
        if text.startswith('**') and text.endswith('**'):
            return text
        
        # –ù–µ —ç–∫—Ä–∞–Ω–∏—Ä—É–µ–º –∫—É—Ä—Å–∏–≤ –≤ *
        if text.startswith('*') and text.endswith('*') and not text.startswith('**'):
            return text
        
        # –≠–∫—Ä–∞–Ω–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –ø—Ä–æ–±–ª–µ–º–∞—Ç–∏—á–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã
        result = text
        for char, escaped in self.escape_chars.items():
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–∏–º–≤–æ–ª—ã, –∫–æ—Ç–æ—Ä—ã–µ —É–∂–µ —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω—ã
            if f'\\{char}' not in result:
                result = result.replace(char, escaped)
        
        return result
    
    def fix_translation_object(self, obj: Any) -> Any:
        """–†–µ–∫—É—Ä—Å–∏–≤–Ω–æ –∏—Å–ø—Ä–∞–≤–ª—è–µ—Ç –æ–±—ä–µ–∫—Ç –ø–µ—Ä–µ–≤–æ–¥–∞."""
        if isinstance(obj, dict):
            return {key: self.fix_translation_object(value) for key, value in obj.items()}
        elif isinstance(obj, list):
            return [self.fix_translation_object(item) for item in obj]
        elif isinstance(obj, str):
            return self.escape_markdown(obj)
        else:
            return obj
    
    def fix_translation_file(self, file_path: Path) -> int:
        """–ò—Å–ø—Ä–∞–≤–ª—è–µ—Ç —Ñ–∞–π–ª –ø–µ—Ä–µ–≤–æ–¥–æ–≤."""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –ø–µ—Ä–µ–≤–æ–¥—ã
            fixed_data = self.fix_translation_object(data)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(fixed_data, f, ensure_ascii=False, indent=2)
            
            print(f"‚úÖ –ò—Å–ø—Ä–∞–≤–ª–µ–Ω —Ñ–∞–π–ª: {file_path}")
            return 1
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–∏ {file_path}: {e}")
            return 0
    
    def fix_all_translations(self) -> int:
        """–ò—Å–ø—Ä–∞–≤–ª—è–µ—Ç –≤—Å–µ —Ñ–∞–π–ª—ã –ø–µ—Ä–µ–≤–æ–¥–æ–≤."""
        locale_dir = Path('bot/i18n/locales')
        fixed_count = 0
        
        if not locale_dir.exists():
            print(f"‚ùå –ü–∞–ø–∫–∞ –ø–µ—Ä–µ–≤–æ–¥–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {locale_dir}")
            return 0
        
        for file_path in locale_dir.glob('*.json'):
            if file_path.is_file():
                fixed_count += self.fix_translation_file(file_path)
        
        return fixed_count
    
    def remove_conflicting_markdown(self, text: str) -> str:
        """–£–¥–∞–ª—è–µ—Ç –∫–æ–Ω—Ñ–ª–∏–∫—Ç—É—é—â–∏–µ —Å–∏–º–≤–æ–ª—ã Markdown."""
        # –£–¥–∞–ª—è–µ–º –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏
        text = re.sub(r'\*\*([^*]+)\*\*', r'\\*\\*\1\\*\\*', text)  # –≠–∫—Ä–∞–Ω–∏—Ä—É–µ–º –∂–∏—Ä–Ω—ã–π —Ç–µ–∫—Å—Ç
        text = re.sub(r'\*([^*]+)\*', r'\\*\1\\*', text)  # –≠–∫—Ä–∞–Ω–∏—Ä—É–µ–º –∫—É—Ä—Å–∏–≤
        text = re.sub(r'_([^_]+)_', r'\\_\1\\_', text)  # –≠–∫—Ä–∞–Ω–∏—Ä—É–µ–º –ø–æ–¥—á–µ—Ä–∫–∏–≤–∞–Ω–∏–µ
        
        return text
    
    def fix_code_strings(self) -> int:
        """–ò—Å–ø—Ä–∞–≤–ª—è–µ—Ç —Å—Ç—Ä–æ–∫–∏ –≤ –∫–æ–¥–µ Python."""
        fixed_count = 0
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã —Ñ–∞–π–ª–æ–≤ –¥–ª—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è
        patterns = [
            'bot/handlers/**/*.py',
            'bot/keyboards/**/*.py',
        ]
        
        for pattern in patterns:
            for file_path in Path('.').glob(pattern):
                if file_path.is_file():
                    try:
                        with open(file_path, 'r', encoding='utf-8') as f:
                            content = f.read()
                        
                        original_content = content
                        
                        # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º —Å—Ç—Ä–æ–∫–∏ —Å parse_mode='Markdown'
                        # –ò—â–µ–º f-—Å—Ç—Ä–æ–∫–∏ –∏ –æ–±—ã—á–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏ —Å –ø—Ä–æ–±–ª–µ–º–Ω—ã–º–∏ —Å–∏–º–≤–æ–ª–∞–º–∏
                        lines = content.split('\n')
                        fixed_lines = []
                        
                        for line in lines:
                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ —Å—Ç—Ä–æ–∫–∞ Markdown
                            if 'parse_mode=' in line and ('Markdown' in line or 'MarkdownV2' in line):
                                # –ò—â–µ–º —Å—Ç—Ä–æ–∫–∏ —Å –Ω–µ—ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ —Å–∏–º–≤–æ–ª–∞–º–∏
                                if re.search(r'[*_`\[\]()~>#+=|{}.!-]', line):
                                    # –ó–∞–º–µ–Ω—è–µ–º –Ω–∞ –±–æ–ª–µ–µ –±–µ–∑–æ–ø–∞—Å–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç
                                    line = re.sub(r'parse_mode=[\'"]Markdown[\'"]', 'parse_mode=\'Markdown\'', line)
                            
                            fixed_lines.append(line)
                        
                        content = '\n'.join(fixed_lines)
                        
                        if content != original_content:
                            with open(file_path, 'w', encoding='utf-8') as f:
                                f.write(content)
                            
                            print(f"‚úÖ –ò—Å–ø—Ä–∞–≤–ª–µ–Ω—ã —Å—Ç—Ä–æ–∫–∏ –≤: {file_path}")
                            fixed_count += 1
                    
                    except Exception as e:
                        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–∏ {file_path}: {e}")
        
        return fixed_count

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è."""
    fixer = MarkdownFixer()
    
    print("üîß –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º —Å Markdown...")
    
    # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º —Ñ–∞–π–ª—ã –ø–µ—Ä–µ–≤–æ–¥–æ–≤
    translation_fixes = fixer.fix_all_translations()
    print(f"üìÑ –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ —Ñ–∞–π–ª–æ–≤ –ø–µ—Ä–µ–≤–æ–¥–æ–≤: {translation_fixes}")
    
    # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –∫–æ–¥ Python
    code_fixes = fixer.fix_code_strings()
    print(f"üêç –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ —Ñ–∞–π–ª–æ–≤ –∫–æ–¥–∞: {code_fixes}")
    
    total_fixes = translation_fixes + code_fixes
    print(f"\n‚úÖ –í—Å–µ–≥–æ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–æ: {total_fixes} —Ñ–∞–π–ª–æ–≤")
    
    if total_fixes > 0:
        print("\nüìù –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:")
        print("1. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —á—Ç–æ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")
        print("2. –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Ç–µ—Å—Ç—ã: python3 -m pytest tests/test_markdown_validation.py")
        print("3. –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä—É–π—Ç–µ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏–π –≤ Telegram")

if __name__ == "__main__":
    main()